<!DOCTYPE html>
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>語音錄製應用</title>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            height: 100vh;
            display: flex;
            flex-direction: column;
            font-family: 'Microsoft JhengHei', sans-serif;
        }
        
        #message-area {
            height: 80vh;
            overflow-y: auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        #control-area {
            height: 20vh;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #ffffff;
            border-top: 1px solid #e0e0e0;
        }
        
        #record-button {
            width: 64px;
            height: 64px;
            border: none;
            border-radius: 50%;
            background-color: #ffffff;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            transition: all 0.3s ease;
        }
        
        #record-button:hover {
            transform: scale(1.1);
        }
        
        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
            background-color: #ffffff;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        
        .recording {
            background-color: #ff4444 !important;
        }
        /* 文本输入框样式 */
        #reference-text {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 12px;
            font-size: 14px;
            transition: border-color 0.3s ease;
        }

        #reference-text:focus {
            border-color: #2196F3;
            outline: none;
        }

        /* 响应式设计 */
        @media (max-width: 768px) {
            #input-section {
                width: 90%;
                margin-right: 0;
            }
        }

        /* 搜尋按鈕容器 */
        .chat-type-buttons {
            display: flex;
            gap: 10px;
            margin-bottom: 10px;
        }
        
        /* 搜尋按鈕樣式 */
        .chat-type-button {
            /* padding: 8px 16px; */
            border: 2px solid #bdbdbd; /* 改為淺灰色邊框 */
            border-radius: 20px;
            background-color: white;
            color: #757575; /* 文字顏色改為中灰色 */
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 14px;
            margin: 15px 0;  /* 增加上下間距 */
            padding: 0 10px;  /* 增加左右內距 */
        }
        
        /* 按鈕被按下的樣式 */
        .chat-type-button.active {
            background-color: #e0e0e0; /* 改為淺灰色背景 */
            color: #424242; /* 文字顏色改為深灰色 */
            border-color: #9e9e9e; /* 邊框顏色改為中灰色 */
        }

        /* 按鈕懸停效果 */
        .chat-type-button:hover {
            background-color: #f5f5f5; /* 非常淺的灰色 */
        }
        
        .chat-type-button.active:hover {
            background-color: #bdbdbd; /* 活動狀態下懸停時稍深的灰色 */
        }
    </style>
</head>
<body>
    <div id="message-area"></div>
    <div id="control-area">
        <!-- <div class="chat-type-button">
            <button id="free-speech-btn" class="chat-type-button active">Free Speech</button>
        </div> -->
        <div id="input-section" style="
            width: 70%; 
            margin-right: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        ">
            
            <!-- 调整后的文本输入框 -->
            <textarea 
                id="reference-text" 
                placeholder="Scenario text will appear here..."
                style="
                    width: 90%;
                    height: 50px;
                    padding: 10px;
                    border: 1px solid #e0e0e0;
                    border-radius: 8px;
                    resize: vertical;
                    font-family: 'Microsoft JhengHei', sans-serif;
                    margin-bottom: 15px;
                    transition: all 0.3s ease;
                "
            ></textarea>
            
            
            <button 
                id="record-button" 
                style="
                    width: 64px;  /* 恢复圆形尺寸 */
                    height: 64px;
                    border-radius: 50%;  /* 圆形设置 */
                    box-shadow: 0 2px 5px rgba(0,0,0,0.2);
                    transition: all 0.3s ease;
                    display: flex;
                    justify-content: center;
                    align-items: center;
                "
            >
                
                <svg id="start-icon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <circle cx="12" cy="12" r="3" fill="currentColor"/>
                </svg>
                <svg id="recording-icon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" style="display: none;">
                    <rect x="5" y="5" width="14" height="14" rx="2" fill="currentColor"/>
                </svg>
            </button>
        </div>
    </div>

    
    <script>
        // Add this at the beginning of your script
        document.addEventListener('DOMContentLoaded', function() {
            // Check if accessing via IP address
            const isIPAddress = /^(?:[0-9]{1,3}\.){3}[0-9]{1,3}$/.test(window.location.hostname);
            if (isIPAddress && window.location.protocol === 'http:') {
                const messageArea = document.getElementById('message-area');
                messageArea.innerHTML = `
                    <div class="message" style="color: #721c24; background-color: #f8d7da; border: 1px solid #f5c6cb; padding: 15px; margin: 10px; border-radius: 5px;">
                        <h3>⚠️ 安全警告</h3>
                        <p>您正在通過 IP 地址訪問此網站。為了使用錄音功能，請：</p>
                        <ol>
                            <li>使用 <a href="http://localhost:8000" style="color: #721c24; text-decoration: underline;">http://localhost:8000</a> 訪問此網站</li>
                            <li>或設置 HTTPS 以使用 IP 地址訪問</li>
                        </ol>
                        <p>當前訪問地址：${window.location.href}</p>
                    </div>
                `;
                // Disable the record button
                const recordButton = document.getElementById('record-button');
                if (recordButton) {
                    recordButton.disabled = true;
                    recordButton.style.opacity = '0.5';
                    recordButton.style.cursor = 'not-allowed';
                }
            }
        });

        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let uploadInterval;
        let silenceTimer = null;
        let fallbackTimer = null;
        let lastAudioLevel = 0;
        let recordingStream = null; // Add this to track the stream
        const SILENCE_THRESHOLD = 0.03; // Increased threshold to filter out more noise
        const SILENCE_DURATION = 3000; // Increased to 3 seconds for complete sentences
        const FALLBACK_INTERVAL = 10000; // Increased to 10 seconds for longer responses
        const MIN_SPEECH_DURATION = 1000; // Minimum 1 second of speech before processing
        let speechStartTime = null;
        let consecutiveSilenceCount = 0;
        const CONSECUTIVE_SILENCE_REQUIRED = 3; // Require multiple silence detections
        
        // Add safeguards for restart mechanism
        let restartCount = 0;
        const MAX_RESTARTS = 15; // Increased from 5 to 15 for better user experience
        const MAX_CHUNKS_PER_SESSION = 30; // Increased from 20 to 30 per user request
        let lastProcessTime = 0;
        const MIN_PROCESS_INTERVAL = 1000; // Reduced from 2000 to 1000ms for more responsive processing

        const messageArea = document.getElementById('message-area');
        const recordButton = document.getElementById('record-button');
        const startIcon = document.getElementById('start-icon');
        const recordingIcon = document.getElementById('recording-icon');
        // const freespeechButton = document.getElementById('free-speech-btn');
        //const referenceTextInput = document.getElementById('reference-text');

        //adjust chat-type-buttons status and outlooks
        //add event listener
        // freespeechButton.addEventListener('click', () => {
        //     chatType = 1;
        //     freespeechButton.classList.add('active');
        //     // tagButton.classList.remove('active');
        //     // webButton.classList.remove('active');
        // });
        
        // 添加訊息到顯示區域
        function addMessage(content, type = 'user') {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message';
            messageDiv.innerHTML = marked.parse(content);
            messageArea.appendChild(messageDiv);
            messageArea.scrollTop = messageArea.scrollHeight;
        }
        
        // 切換錄音狀態
        function toggleRecording() {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        }
        
        // Function to calculate audio level
        function calculateAudioLevel(audioData) {
            // Use RMS (Root Mean Square) for better noise filtering
            let sumOfSquares = 0;
            for (let i = 0; i < audioData.length; i++) {
                sumOfSquares += audioData[i] * audioData[i];
            }
            const rms = Math.sqrt(sumOfSquares / audioData.length);
            
            // Apply smoothing to reduce sensitivity to brief spikes
            lastAudioLevel = lastAudioLevel * 0.7 + rms * 0.3;
            return lastAudioLevel;
        }

        // Function to handle silence detection
        function handleSilenceDetection(audioContext, stream) {
            const analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);
            analyser.fftSize = 2048;
            analyser.smoothingTimeConstant = 0.8; // Increased smoothing for noise reduction
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Float32Array(bufferLength);
            
            function checkAudioLevel() {
                if (!isRecording) return;
                
                analyser.getFloatTimeDomainData(dataArray);
                const audioLevel = calculateAudioLevel(dataArray);
                
                // Determine if this is speech or noise
                const isSpeech = audioLevel > SILENCE_THRESHOLD;
                
                // Visual feedback - different colors for speech vs silence vs noise
                if (isSpeech) {
                    recordButton.style.backgroundColor = '#4caf50'; // Green when clear speech detected
                    if (!speechStartTime) {
                        speechStartTime = Date.now();
                        console.log('Speech started at:', speechStartTime);
                    }
                    consecutiveSilenceCount = 0; // Reset silence counter
                } else {
                    recordButton.style.backgroundColor = '#ff4444'; // Red when silent
                    consecutiveSilenceCount++;
                }
                
                // Debug logging with less frequency but more info
                if (Math.random() < 0.05) { // Log only 5% of the time
                    console.log('Audio level:', audioLevel.toFixed(4), 
                              'Threshold:', SILENCE_THRESHOLD, 
                              'Speech:', isSpeech,
                              'Silence count:', consecutiveSilenceCount,
                              'Speech duration:', speechStartTime ? Date.now() - speechStartTime : 0);
                }
                
                // Handle silence detection with consecutive requirement
                if (!isSpeech && consecutiveSilenceCount >= CONSECUTIVE_SILENCE_REQUIRED) {
                    if (!silenceTimer && speechStartTime) {
                        const speechDuration = Date.now() - speechStartTime;
                        if (speechDuration >= MIN_SPEECH_DURATION) {
                            console.log('Sufficient silence detected after', speechDuration, 'ms of speech, starting timer...');
                            silenceTimer = setTimeout(() => {
                                if (isRecording && audioChunks.length > 0) {
                                    console.log('Processing speech segment - Duration:', speechDuration, 'ms, Chunks:', audioChunks.length);
                                    processCompleteRecording();
                                    speechStartTime = null; // Reset speech timer
                                }
                                silenceTimer = null;
                                consecutiveSilenceCount = 0;
                            }, SILENCE_DURATION);
                        } else {
                            console.log('Speech too short (', speechDuration, 'ms), ignoring...');
                            speechStartTime = null;
                            consecutiveSilenceCount = 0;
                        }
                    }
                } else if (isSpeech) {
                    if (silenceTimer) {
                        console.log('Speech resumed, cancelling silence timer. Audio level:', audioLevel.toFixed(4));
                        clearTimeout(silenceTimer);
                        silenceTimer = null;
                        consecutiveSilenceCount = 0;
                    }
                }
                
                requestAnimationFrame(checkAudioLevel);
            }
            
            checkAudioLevel();
        }

        // 開始錄音
        async function startRecording() {
            try {
                console.log('Starting recording...');
                
                // Reset restart count for new recording session
                restartCount = 0;
                lastProcessTime = 0;
                speechStartTime = null;
                consecutiveSilenceCount = 0;
                lastAudioLevel = 0;
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        sampleSize: 16,
                        volume: 1.0,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                recordingStream = stream; // Store the stream reference
                console.log('Got media stream');
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Resume audio context if it's suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }
                
                handleSilenceDetection(audioContext, stream);
                
                // Check supported MIME types with fallback options
                const mimeTypes = [
                    'audio/webm;codecs=opus',
                    'audio/webm;codecs=vp8,opus',
                    'audio/webm',
                    'audio/mp4;codecs=mp4a.40.2',
                    'audio/mp4',
                    'audio/mpeg',
                    'audio/wav'
                ];
                
                let selectedMimeType = '';
                let selectedOptions = {};
                
                console.log('Checking supported MIME types...');
                for (const mimeType of mimeTypes) {
                    const supported = MediaRecorder.isTypeSupported(mimeType);
                    console.log(`${mimeType}: ${supported ? 'SUPPORTED' : 'not supported'}`);
                    if (supported && !selectedMimeType) {
                        selectedMimeType = mimeType;
                        console.log('Selected MIME type:', selectedMimeType);
                    }
                }
                
                if (selectedMimeType) {
                    selectedOptions = {
                        mimeType: selectedMimeType,
                        audioBitsPerSecond: 128000
                    };
                } else {
                    console.warn('No supported MIME type found, using default');
                    selectedOptions = {
                        audioBitsPerSecond: 128000
                    };
                }
                
                console.log('MediaRecorder options:', selectedOptions);
                
                try {
                    mediaRecorder = new MediaRecorder(stream, selectedOptions);
                    console.log('MediaRecorder created successfully with options');
                } catch (recordeError) {
                    console.warn('Failed to create MediaRecorder with options, trying with default:', recordeError);
                    try {
                        mediaRecorder = new MediaRecorder(stream);
                        console.log('MediaRecorder created with default options');
                    } catch (defaultError) {
                        console.error('Failed to create MediaRecorder even with default options:', defaultError);
                        throw defaultError;
                    }
                }
                
                // Reset audioChunks for new recording
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    console.log('Data available, size:', event.data.size, 'type:', event.data.type);
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        console.log('Total chunks collected:', audioChunks.length);
                    }
                };

                mediaRecorder.onerror = (event) => {
                    console.error('MediaRecorder error:', event.error);
                    addMessage(`❌ Recording error: ${event.error}`);
                };

                mediaRecorder.onstart = () => {
                    console.log('MediaRecorder started with MIME type:', mediaRecorder.mimeType);
                };

                mediaRecorder.onstop = () => {
                    console.log('MediaRecorder stopped, processing final recording...');
                    if (audioChunks.length > 0) {
                        processCompleteRecording();
                    }
                };

                // Start recording with 1 second timeslice to generate data chunks
                mediaRecorder.start(1000);
                isRecording = true;
                recordButton.classList.add('recording');
                startIcon.style.display = 'none';
                recordingIcon.style.display = 'block';
                
                // Add fallback timer to ensure chunks are processed even without silence detection
                fallbackTimer = setInterval(() => {
                    if (isRecording && audioChunks.length > 0) {
                        console.log('Fallback timer triggered - processing recording');
                        processCompleteRecording();
                    }
                }, FALLBACK_INTERVAL);
                
                addMessage('🎤 Recording started... Speak clearly and pause for 3 seconds after completing your sentence. The button will be GREEN when speech is detected, RED when silent. Minimum 1 second of speech required.');

            } catch (err) {
                console.error('Error accessing microphone:', err);
                addMessage(`❌ Error accessing microphone: ${err.message}`);
            }
        }
        
        // 停止錄音
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                console.log('Stopping recording...');
                
                // Clear all timers first
                if (silenceTimer) {
                    clearTimeout(silenceTimer);
                    silenceTimer = null;
                }
                if (fallbackTimer) {
                    clearInterval(fallbackTimer);
                    fallbackTimer = null;
                }
                
                isRecording = false;
                recordButton.classList.remove('recording');
                recordButton.style.backgroundColor = ''; // Reset button color
                startIcon.style.display = 'block';
                recordingIcon.style.display = 'none';
                
                // Stop the media recorder - this will trigger onstop event
                mediaRecorder.stop();
                
                // Stop all tracks in the stream
                if (recordingStream) {
                    recordingStream.getTracks().forEach(track => track.stop());
                    recordingStream = null;
                }
                
                // Reset all state variables
                speechStartTime = null;
                consecutiveSilenceCount = 0;
                lastAudioLevel = 0;
                restartCount = 0;
                lastProcessTime = 0;
                
                addMessage('🛑 Recording stopped.');
            }
        }
        
        // Process a complete recording segment and restart recording
        async function processCompleteRecording() {
            const currentTime = Date.now();
            
            // Check if we're processing too frequently - but allow bypass for important chunks
            if (currentTime - lastProcessTime < MIN_PROCESS_INTERVAL && audioChunks.length < 5) {
                console.log('Processing too frequently with few chunks, skipping...');
                return;
            }
            
            if (audioChunks.length === 0) {
                console.log('No audio chunks to process');
                return;
            }
            
            // Limit chunks to prevent memory issues
            if (audioChunks.length > MAX_CHUNKS_PER_SESSION) {
                console.warn('Too many chunks accumulated (', audioChunks.length, '), limiting to', MAX_CHUNKS_PER_SESSION);
                audioChunks = audioChunks.slice(0, MAX_CHUNKS_PER_SESSION);
            }

            console.log('Processing complete recording with', audioChunks.length, 'chunks');
            lastProcessTime = currentTime;
            
            // Create a copy of current chunks and clear the array for next recording
            const recordingChunks = [...audioChunks];
            audioChunks = [];
            
            // Stop current recording
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            
            // Process the recording
            const success = await uploadCompleteRecording(recordingChunks);
            
            // Auto-reset restart count if we've reached the limit to ensure continuous operation
            if (restartCount >= MAX_RESTARTS) {
                console.log('Reached restart limit, auto-resetting for continuous operation...');
                restartCount = 0;
                addMessage('🔄 Recording session auto-reset for continuous operation.');
            }
            
            // Always restart if processing was successful and we're still recording
            if (success && isRecording && recordingStream) {
                setTimeout(() => {
                    restartRecording();
                }, 500);
            } else if (!success) {
                console.warn('Upload failed, will retry on next speech segment');
                // Don't stop recording, just continue listening for next speech
                if (isRecording && recordingStream) {
                    setTimeout(() => {
                        restartRecording();
                    }, 1000); // Longer delay on failure
                }
            }
        }
        
        // Restart recording with the existing stream
        function restartRecording() {
            if (!isRecording || !recordingStream) {
                console.log('Cannot restart: not recording or no stream');
                return;
            }
            
            restartCount++;
            console.log('Restarting recording... (attempt', restartCount, ')');
            
            try {
                // Create new MediaRecorder with same settings
                const mimeType = mediaRecorder ? mediaRecorder.mimeType : 'audio/webm;codecs=opus';
                const options = {
                    mimeType: mimeType,
                    audioBitsPerSecond: 128000
                };
                
                try {
                    mediaRecorder = new MediaRecorder(recordingStream, options);
                } catch (e) {
                    console.warn('Failed to create MediaRecorder with options, using default');
                    mediaRecorder = new MediaRecorder(recordingStream);
                }
                
                // Reset chunks array and speech detection variables
                audioChunks = [];
                speechStartTime = null;
                consecutiveSilenceCount = 0;
                lastAudioLevel = 0;
                
                // Set up event handlers
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        // Log less frequently to reduce console spam
                        if (audioChunks.length % 15 === 0) {
                            console.log('Chunks collected:', audioChunks.length);
                        }
                    }
                };
                
                mediaRecorder.onstop = () => {
                    if (audioChunks.length > 0 && isRecording) {
                        processCompleteRecording();
                    }
                };
                
                mediaRecorder.onerror = (event) => {
                    console.error('MediaRecorder error during restart:', event.error);
                    addMessage(`❌ Recording error: ${event.error}. Attempting to continue...`);
                    // Try to restart once more instead of stopping completely
                    if (restartCount < MAX_RESTARTS) {
                        setTimeout(() => {
                            restartRecording();
                        }, 2000);
                    }
                };
                
                // Start new recording with same timeslice
                mediaRecorder.start(1000);
                console.log('Recording restarted successfully');
                
            } catch (error) {
                console.error('Error restarting recording:', error);
                addMessage('❌ Error restarting recording. Attempting to continue...');
                // Try to restart once more instead of stopping completely
                if (restartCount < MAX_RESTARTS) {
                    setTimeout(() => {
                        restartRecording();
                    }, 2000);
                }
            }
        }
        
        async function uploadCompleteRecording(recordingChunks) {
            if (recordingChunks.length === 0) {
                console.log('No recording chunks to upload');
                return false;
            }

            console.log('Uploading complete recording with', recordingChunks.length, 'chunks');
            
            // Determine the best MIME type for the blob based on what was recorded
            let blobMimeType = 'audio/webm;codecs=opus';
            let fileExtension = 'webm';
            
            if (mediaRecorder && mediaRecorder.mimeType) {
                blobMimeType = mediaRecorder.mimeType;
                console.log('Using recorded MIME type:', blobMimeType);
                
                // Determine file extension based on MIME type
                if (blobMimeType.includes('webm')) {
                    fileExtension = 'webm';
                } else if (blobMimeType.includes('mp4')) {
                    fileExtension = 'mp4';
                } else if (blobMimeType.includes('wav')) {
                    fileExtension = 'wav';
                } else if (blobMimeType.includes('mpeg')) {
                    fileExtension = 'mp3';
                }
            }

            const audioBlob = new Blob(recordingChunks, { 
                type: blobMimeType
            });

            console.log('Audio blob details:');
            console.log('- Size:', audioBlob.size, 'bytes');
            console.log('- Type:', audioBlob.type);
            console.log('- Extension:', fileExtension);
            console.log('- Chunks count:', recordingChunks.length);

            // Verify blob has content
            if (audioBlob.size === 0) {
                console.warn('Empty audio blob, skipping upload');
                return false;
            }
            
            if (audioBlob.size < 1000) { // Increase minimum size threshold
                console.warn('Very small audio blob, might be too short for meaningful content');
                // Still try to process it
            }

            const formData = new FormData();
            const filename = `recording_${Date.now()}.${fileExtension}`;
            formData.append('audio', audioBlob, filename);
            
            console.log('Uploading file:', filename);

            try {
                console.log('Sending request to /transcribe-chunk');
                const response = await fetch('/transcribe-chunk', {
                    method: 'POST',
                    body: formData
                });

                console.log('Response status:', response.status);
                
                const data = await response.json();
                console.log('Response data:', data);
                
                // Check if server returned completely empty response
                const hasTranscription = data.transcription && data.transcription.trim();
                const hasChatResponse = data.chat_response && data.chat_response.trim();
                const hasError = data.error && data.error.trim();
                
                if (!hasTranscription && !hasChatResponse && !hasError) {
                    console.warn('Server returned completely empty response - this might indicate a processing issue');
                    addMessage('⚠️ No response from server. The audio might be too quiet or unclear. Please try speaking louder and clearer.');
                    return false; // Return false to prevent restart loop
                }
                
                // Handle response even if there's an error
                if (hasError) {
                    console.error('Server error:', data.error);
                    // Only show error in UI if it's not a processing error that we can retry
                    if (!data.error.includes('audio file format') && !data.error.includes('conversion')) {
                        addMessage(`⚠️ ${data.error}`);
                    }
                    
                    // Still show any partial results
                    if (hasTranscription) {
                        const userMessage = document.createElement('div');
                        userMessage.className = 'message user-message';
                        userMessage.style.backgroundColor = '#fff3cd';
                        userMessage.style.borderLeft = '4px solid #ffc107';
                        userMessage.innerHTML = `<strong>You (partial):</strong> ${data.transcription}`;
                        messageArea.appendChild(userMessage);
                    }
                    
                    if (hasChatResponse) {
                        const botMessage = document.createElement('div');
                        botMessage.className = 'message bot-message';
                        botMessage.style.backgroundColor = '#f8d7da';
                        botMessage.style.borderLeft = '4px solid #dc3545';
                        botMessage.innerHTML = `<strong>Bot:</strong> ${data.chat_response}`;
                        messageArea.appendChild(botMessage);
                    }
                    
                    return false; // Return false for errors to prevent restart
                } else {
                    // Normal successful response
                    if (hasTranscription) {
                        const userMessage = document.createElement('div');
                        userMessage.className = 'message user-message';
                        userMessage.style.backgroundColor = '#e3f2fd';
                        userMessage.style.borderLeft = '4px solid #2196f3';
                        userMessage.innerHTML = `<strong>You:</strong> ${data.transcription}`;
                        messageArea.appendChild(userMessage);
                    }

                    if (hasChatResponse) {
                        const botMessage = document.createElement('div');
                        botMessage.className = 'message bot-message';
                        botMessage.style.backgroundColor = '#f3e5f5';
                        botMessage.style.borderLeft = '4px solid #9c27b0';
                        botMessage.innerHTML = `<strong>Bot:</strong> ${data.chat_response}`;
                        messageArea.appendChild(botMessage);
                    }
                }

                // Scroll to bottom
                messageArea.scrollTop = messageArea.scrollHeight;
                
                return true; // Return true for successful processing
                
            } catch (error) {
                console.error('Error uploading complete recording:', error);
                addMessage(`❌ Upload error: ${error.message}. Please try again.`);
                return false; // Return false for network errors
            }
        }
        
        // Keep the old function name for compatibility but redirect to new function
        async function uploadAudioChunk() {
            return uploadCompleteRecording(audioChunks);
        }

        recordButton.addEventListener('click', toggleRecording);

        // Add this at the beginning of your existing script
        document.addEventListener('DOMContentLoaded', function() {
            // Get data from localStorage
            const scenarioText = localStorage.getItem('scenarioText');
            const selectedTopic = localStorage.getItem('selectedTopic');
            const selectedLevel = localStorage.getItem('selectedLevel');
            const selectedSegmentation = localStorage.getItem('selectedSegmentation');
            
            // Display scenario text
            if (scenarioText) {
                document.getElementById('reference-text').value = scenarioText;
            }
            
            // Clear localStorage after retrieving data
            localStorage.removeItem('scenarioText');
            localStorage.removeItem('selectedTopic');
            localStorage.removeItem('selectedLevel');
            localStorage.removeItem('selectedSegmentation');
        });

        // Manual reset function for when things go wrong
        function resetRecordingSession() {
            console.log('Manually resetting recording session...');
            
            // Stop current recording completely
            if (isRecording) {
                stopRecording();
            }
            
            // Clear all state
            audioChunks = [];
            restartCount = 0;
            lastProcessTime = 0;
            speechStartTime = null;
            consecutiveSilenceCount = 0;
            lastAudioLevel = 0;
            
            // Clear any remaining timers
            if (silenceTimer) {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }
            if (fallbackTimer) {
                clearInterval(fallbackTimer);
                fallbackTimer = null;
            }
            
            // Reset UI
            recordButton.style.backgroundColor = '';
            recordButton.classList.remove('recording');
            startIcon.style.display = 'block';
            recordingIcon.style.display = 'none';
            
            addMessage('🔄 Recording session reset. You can now start recording again.');
        }
        
        // Add double-click to reset functionality
        recordButton.addEventListener('dblclick', resetRecordingSession);
    </script>
    <style>
        /* 新增响应式设计 */
        @media (max-width: 768px) {
            #input-section {
                width: 90%;
            }
            #reference-text {
                width: 100%;  /* 小屏幕时占满宽度 */
            }
        }

        /* 按钮交互优化 */
        #record-button:hover {
            transform: scale(1.1);
            background-color: #f8f8f8;
        }

        #record-button:active {
            transform: scale(0.95);
        }

        /* 输入框聚焦效果 */
        #reference-text:focus {
            border-color: #2196F3;
            box-shadow: 0 0 5px rgba(33,150,243,0.3);
        }
    </style>
</body>
</html>

    
    
