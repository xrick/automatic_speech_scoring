{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf2965f-04e5-463f-991e-7ca29f4e2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132ca80c-13ee-4cb6-90ec-f4781bcb50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5b8110-a3bb-4b33-99fd-fc7a898cca42",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '../../web/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", download_root=model_path, local_files_only=True) #home\u001b[39;00m\n\u001b[32m      7\u001b[39m model = WhisperModel(model_size, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m, compute_type=\u001b[33m\"\u001b[39m\u001b[33mint8\u001b[39m\u001b[33m\"\u001b[39m, local_files_only=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#office use defult dir\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m segments, info = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../../web/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDetected language \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m with probability \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m\"\u001b[39m % (info.language, info.language_probability))\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segments:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/resenv/lib/python3.11/site-packages/faster_whisper/transcribe.py:834\u001b[39m, in \u001b[36mWhisperModel.transcribe\u001b[39m\u001b[34m(self, audio, language, task, log_progress, beam_size, best_of, patience, length_penalty, repetition_penalty, no_repeat_ngram_size, temperature, compression_ratio_threshold, log_prob_threshold, no_speech_threshold, condition_on_previous_text, prompt_reset_on_temperature, initial_prompt, prefix, suppress_blank, suppress_tokens, without_timestamps, max_initial_timestamp, word_timestamps, prepend_punctuations, append_punctuations, multilingual, vad_filter, vad_parameters, max_new_tokens, chunk_length, clip_timestamps, hallucination_silence_threshold, hotwords, language_detection_threshold, language_detection_segments)\u001b[39m\n\u001b[32m    831\u001b[39m     multilingual = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, np.ndarray):\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     audio = \u001b[43mdecode_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m duration = audio.shape[\u001b[32m0\u001b[39m] / sampling_rate\n\u001b[32m    837\u001b[39m duration_after_vad = duration\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/resenv/lib/python3.11/site-packages/faster_whisper/audio.py:46\u001b[39m, in \u001b[36mdecode_audio\u001b[39m\u001b[34m(input_file, sampling_rate, split_stereo)\u001b[39m\n\u001b[32m     43\u001b[39m raw_buffer = io.BytesIO()\n\u001b[32m     44\u001b[39m dtype = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mav\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m container:\n\u001b[32m     47\u001b[39m     frames = container.decode(audio=\u001b[32m0\u001b[39m)\n\u001b[32m     48\u001b[39m     frames = _ignore_invalid_frames(frames)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/resenv/lib/python3.11/site-packages/av/container/core.pyx:418\u001b[39m, in \u001b[36mav.container.core.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/resenv/lib/python3.11/site-packages/av/container/core.pyx:283\u001b[39m, in \u001b[36mav.container.core.Container.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/resenv/lib/python3.11/site-packages/av/container/core.pyx:303\u001b[39m, in \u001b[36mav.container.core.Container.err_check\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/resenv/lib/python3.11/site-packages/av/error.pyx:423\u001b[39m, in \u001b[36mav.error.err_check\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: '../../web/'"
     ]
    }
   ],
   "source": [
    "# model_size = \"distil-large-v3\"\n",
    "model_size = \"distil-small.en\"\n",
    "# model_path = \"/Users/xrickliao/WorkSpaces/LLM_Repo/models/Whisper/Models/faster_distil_whisper_large_v3_snapdwn/\" #home\n",
    "\n",
    "model_path = \"/home/mapleleaf/LCJRepos/LLM_Models/faster_whisper/ditil_large_v3/models--Systran--faster-distil-whisper-large-v3/\" #office\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", download_root=model_path, local_files_only=True) #home\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\", local_files_only=False) #office use defult dir\n",
    "\n",
    "segments, info = model.transcribe(\"../../web/\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c432463-eda6-4d9a-9280-1ab46fb98a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
