{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca02e4c-fc70-4186-9f6c-5a065296cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xrickliao/miniconda3/miniconda3/envs/llmenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcd4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad86163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2183c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import time\n",
    "import pyaudio\n",
    "import wave\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34e5286a-4d83-47b7-8cde-dc98b88849c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e16aa48-18bd-48e9-bef8-27ee5ddf2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure 語音服務配置\n",
    "SUB_KEY = \"7c400507-6b30-4a2f-97f9-5baa6c9e4e28\"\n",
    "SPEECH_KEY1 = \"02KqGB8EDonpmVbrFYwd5Dm7cGdvR7e3jdUdaVDiRqRYq8kCaaSUJQQJ99BCACYeBjFXJ3w3AAAYACOGE4wU\"#os.getenv(\"AZURE_SPEECH_KEY\", \"your_speech_key\")expired.\n",
    "SPEECH_KEY2 = \"EcmC2LZuRPawifYzH6XIjkq3yz6Jsr0XPHSYDebAO2YfDqmjaA8dJQQJ99BCACYeBjFXJ3w3AAAYACOGDE2q\"\n",
    "SPEECH_REGION = \"eastUS\"#os.getenv(\"AZURE_SPEECH_REGION\", \"your_region\")\n",
    "\n",
    "WHISPER_MODEL_TYPE = \"distil-large-v3\";\n",
    "WHISPER_MODEL_PATH = \"/Users/xrickliao/WorkSpaces/LLM_Repo/models/Whisper/Models/faster_distil_whisper_large_v3_snapdwn/\";\n",
    "whisper_model=None;\n",
    "LLM_MODEL='phi4:latest';\n",
    "SPELL_CORRECT_PROMPT='''\n",
    "    role:you are a perfect english spelling checker.\n",
    "    task:\n",
    "    1.please do spelling checking for the following senteces.\n",
    "    2.Do not change the style, form, and structure of the sentences.\n",
    "    3.only return the corrected sentences\n",
    "    sentences:\\n{0}\\n\n",
    "'''\n",
    "llm=None;\n",
    "STEAM_SAVE_DIR=\"./mic_record_savedir/{}\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a531f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = WhisperModel(WHISPER_MODEL_TYPE, device=\"cpu\", compute_type=\"int8\", download_root=WHISPER_MODEL_PATH, local_files_only=True)\n",
    "llm = OllamaLLM(model=LLM_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d8b23-ea66-45fa-8f2d-7fa6ca3b8ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755cfea6-6b4e-4cfe-a06f-5a9ee3ed8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pronunciation_assessment(audio_file: str, reference_text: str) -> dict:\n",
    "    \"\"\"執行發音評估\"\"\"\n",
    "    # try:\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=SUB_KEY, \n",
    "        region=SPEECH_REGION\n",
    "    )\n",
    "    \n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
    "    \n",
    "    # 創建發音評估配置\n",
    "    pronunciation_config = speechsdk.PronunciationAssessmentConfig(\n",
    "        reference_text=reference_text,\n",
    "        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,\n",
    "        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,\n",
    "        enable_miscue=True\n",
    "    )\n",
    "    pronunciation_config.enable_prosody_assessment()\n",
    "    \n",
    "    # 創建語音識別器\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, \n",
    "        audio_config=audio_config,\n",
    "        language=\"en-US\"  # 可根據需求修改語言\n",
    "    )\n",
    "    \n",
    "    # 應用發音評估配置\n",
    "    pronunciation_config.apply_to(speech_recognizer)\n",
    "    \n",
    "    # 執行識別\n",
    "    result = speech_recognizer.recognize_once_async().get()\n",
    "    \n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        pronunciation_result = speechsdk.PronunciationAssessmentResult(result)\n",
    "        return {\n",
    "            \"recognized_text\": result.text,\n",
    "            \"accuracy_score\": pronunciation_result.accuracy_score,\n",
    "            \"pronunciation_score\": pronunciation_result.pronunciation_score,\n",
    "            \"completeness_score\": pronunciation_result.completeness_score,\n",
    "            \"fluency_score\": pronunciation_result.fluency_score,\n",
    "            \"prosody_score\": pronunciation_result.prosody_score,\n",
    "            \"words\": [\n",
    "                {\n",
    "                    \"word\": word.word,\n",
    "                    \"accuracy_score\": word.accuracy_score,\n",
    "                    \"error_type\": word.error_type\n",
    "                }\n",
    "                for word in pronunciation_result.words\n",
    "            ]\n",
    "        }\n",
    "    else:\n",
    "        raise Exception(f\"Speech recognition failed: {result.reason}\")\n",
    "            \n",
    "    # except Exception as e:\n",
    "    #     raise Exception(f\"Pronunciation assessment failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2ef275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ref_text(audio_file:str=None):\n",
    "    segments, info = whisper_model.transcribe(audio_file,  beam_size=5, language=\"en\")\n",
    "    # print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "    trans_txt = \"\";\n",
    "    for segment in segments:\n",
    "        print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "        trans_txt += segment.text\n",
    "        \n",
    "    \n",
    "    ref_txt = llm.invoke(SPELL_CORRECT_PROMPT.format(trans_txt));\n",
    "    print(f\"the corrected transcribe text:\\n{trans_txt}\");\n",
    "    return ref_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93fb2123-4026-470d-8562-df5cfbe52b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 10.00s]  Network protein is a technique used in debiland to reduce the size and complexity of a neural network by eliminating unnecessary.\n",
      "the corrected transcribe text:\n",
      " Network protein is a technique used in debiland to reduce the size and complexity of a neural network by eliminating unnecessary.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Speech recognition failed: ResultReason.Canceled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m test_audio = \u001b[33m\"\u001b[39m\u001b[33m./mic_record_savedir/mic_test_sound_20250316215157.wav\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;66;03m#\"../../../web/recordings/recording_20250309_085027.wav\"\u001b[39;00m\n\u001b[32m      2\u001b[39m _ref_txt = gen_ref_text(audio_file=test_audio)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mperform_pronunciation_assessment\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_audio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ref_txt\u001b[49m\u001b[43m)\u001b[49m;\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mperform_pronunciation_assessment\u001b[39m\u001b[34m(audio_file, reference_text)\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrecognized_text\u001b[39m\u001b[33m\"\u001b[39m: result.text,\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maccuracy_score\u001b[39m\u001b[33m\"\u001b[39m: pronunciation_result.accuracy_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m         ]\n\u001b[32m     50\u001b[39m     }\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSpeech recognition failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: Speech recognition failed: ResultReason.Canceled"
     ]
    }
   ],
   "source": [
    "test_audio = \"./mic_record_savedir/mic_test_sound_20250316215157.wav\"#\"../../../web/recordings/recording_20250309_085027.wav\"\n",
    "_ref_txt = gen_ref_text(audio_file=test_audio)\n",
    "perform_pronunciation_assessment(audio_file=test_audio, reference_text=_ref_txt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862049d-dfd3-41c4-9462-c9d5b70aac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db9b64eb-29fe-492b-92b1-2ea43718e094",
   "metadata": {},
   "source": [
    "#### 麥克風錄音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc1e51-e7d9-497f-a65f-782edafd323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1 #if sys.platform == 'darwin' else 2;\n",
    "RATE = 20000\n",
    "RECORD_SECONDS = 1.5\n",
    "SAMPLE_SIZE = 2\n",
    "FRAMES_PER_BUFFER = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2382c891-4014-4b6f-b33f-d9d88fbfa567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_sound(record_second=10):\n",
    "    RECORD_SECONDS = record_second;\n",
    "    WAVE_OUTPUT_FILENAME = \"mic_test_sound_{}.wav\".format(genDataTimeStr());\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    output=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    \n",
    "    print(f\"進行{record_second}秒聲音錄製..........\")\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    for i in range(0, int(RATE / CHUNK * record_second)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    # stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    test_wav = \"./mic_record_savedir/{}\".format(WAVE_OUTPUT_FILENAME);\n",
    "    wf = wave.open(test_wav, 'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    print(\"錄製完成，進行辨識{}\".format(test_wav));\n",
    "    return test_wav;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91f8839c-8b36-41ba-bd85-c12aac33bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_sound();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53f3f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stream_recording_from_mic():\n",
    "#     p = pyaudio.PyAudio()\n",
    "#     stream_save_wav_name = \"stream_save_{}.wav\"\n",
    "#     frames = []\n",
    "#     max_frames =  (RATE * RECORD_SECONDS) / FRAMES_PER_BUFFER\n",
    "    \n",
    "#     def callback(in_data, frame_count, time_info, status):\n",
    "#         # print(\"callback first line is called\")\n",
    "#         frames.append(np.frombuffer(in_data, dtype=np.int16))\n",
    "#         if len(frames) > max_frames:\n",
    "#             # print(\"callback if is called\")\n",
    "#             # print(f\"len of frames:{len(frames)}\")\n",
    "#             frames.pop(0)\n",
    "#         return (in_data, pyaudio.paContinue)\n",
    "    \n",
    "#     start_t = time.time() \n",
    "#     stream = p.open(format=FORMAT,\n",
    "#                     channels=CHANNELS,\n",
    "#                     rate=RATE,\n",
    "#                     input=True,\n",
    "#                     frames_per_buffer=FRAMES_PER_BUFFER,\n",
    "#                     stream_callback=callback)\n",
    "    \n",
    "#     stream.start_stream()\n",
    "    \n",
    "#     use_fft = False\n",
    "    \n",
    "#     while True:\n",
    "#         try:\n",
    "#             if len(frames) >= max_frames:\n",
    "#                 save_frames = frames.copy()\n",
    "#                 sound_data = np.array(save_frames.copy());\n",
    "#                 frames = [];\n",
    "#                 test_save_name = STEAM_SAVE_DIR.format(stream_save_wav_name.format(genDataTimeStr()));\n",
    "#                 wf = wave.open(test_save_name, 'wb')\n",
    "#                 wf.setnchannels(1)\n",
    "#                 wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "#                 wf.setframerate(RATE)\n",
    "#                 wf.writeframes(b''.join(save_frames))\n",
    "#                 wf.close();\n",
    "#                 print(\"wav:{} saved\".format(test_save_name))\n",
    "#             time.sleep(1)\n",
    "#         except KeyboardInterrupt:\n",
    "#             break;\n",
    "#     print(\"stop stream\")\n",
    "    \n",
    "#     # stop stream (6)\n",
    "#     stream.stop_stream()\n",
    "#     stream.close()\n",
    "#     p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c3263-f170-4ea2-8f7a-012d25322e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011a29e-1b0d-4930-a320-41fb15ada352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
